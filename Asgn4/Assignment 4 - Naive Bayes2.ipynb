{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "610f3d52",
      "metadata": {
        "id": "610f3d52"
      },
      "source": [
        "# Assignment 4 Naive Bayes Classifier\n",
        "\n",
        "For this assignment you will implement a Naive Bayes Classifier that implements the SKlearn classifier API with `fit`, `predict` and `score` methods.\n",
        "\n",
        "The Naive Bayes Classifer takes as parameter the density function used in the likelihood calcuation: \n",
        "* `normal`: Normal density function\n",
        "* `knn`: K nearest neighbor density function\n",
        "\n",
        "Most of the code already has been written for you. You only need to fill in the missing part between \n",
        "```\n",
        "## Insert your code BEGIN\n",
        "\n",
        "## Insert your code END\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57d846e0",
      "metadata": {
        "id": "57d846e0"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "560edeae",
      "metadata": {
        "id": "560edeae"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, likelihood='normal', k=None):\n",
        "        self.likelihood = likelihood\n",
        "        \n",
        "        # Let\n",
        "        #  K = number of unique classes\n",
        "        #  N = number of test instances\n",
        "        #  d = number of inputs (input dimensionality)\n",
        "\n",
        "        # Numpy array unique classes, shape = (K,)\n",
        "        self.classes = None\n",
        "        \n",
        "        # Numpy array of class priors, P(C), shape = (K,)\n",
        "        self.priors = None\n",
        "       \n",
        "        # Numpy array of likelihoods, P(x|C), shape = (N, K),\n",
        "        self.likelihoods = None\n",
        "\n",
        "        # Numpy array of posterior probabilities, P(C|x), shape = (N, K)\n",
        "        self.posteriors = None\n",
        "        \n",
        "        ## For the Guassian Density \n",
        "        # means, shape = (K, d)\n",
        "        self.avgs = None\n",
        "        # variances, shape = (K, d)\n",
        "        self.vars = None\n",
        "        \n",
        "        ## For the knn Density\n",
        "        # number of neighbors to use\n",
        "        self.k = k\n",
        "        # store training X\n",
        "        self.X_train = None\n",
        "        # store trainging y\n",
        "        self.y_train = None\n",
        "\n",
        "    \n",
        "    def generate_classes(self, y):\n",
        "        \"\"\"\n",
        "        Generate the classes based on y, and store in self.classes\n",
        "\n",
        "        :param y: array of class targets\n",
        "        \"\"\"\n",
        "        self.classes = np.unique(y)\n",
        "        # print(self.classes)\n",
        "        \n",
        "    def generate_priors(self, y):\n",
        "        \"\"\"\n",
        "        Compute the prior probabilities and store self.priors\n",
        "\n",
        "        :param y: array of class targets\n",
        " \n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "        # print(class_counts)\n",
        "        self.priors = class_counts/len(y)\n",
        "        \n",
        "        ## Insert your code END\n",
        "    \n",
        "\n",
        "    def knn_density_function(self, x_train, x_predict): \n",
        "        \"\"\"\n",
        "        Implements k-nearest neighbor density estimate (Alpaydin Eq 8.8)\n",
        "\n",
        "        :param x_train 1d numpy array\n",
        "        :param x_predict 1d numpy array\n",
        "        :returns probabilities at x_prdict, shape = x_predict.shape\n",
        "        \"\"\"\n",
        "        # Find the distance to kth nearest neighbor\n",
        "        result = []\n",
        "        for x0 in x_predict:\n",
        "            dist = np.abs(x_train - x0)\n",
        "            index = np.argsort(dist)\n",
        "            result.append(dist[index==self.k - 1][0])\n",
        "        dist_k = np.array(result)\n",
        "        \n",
        "        # Find the probability at x using knn density\n",
        "        # Note: Equation 8.8 may return probabilites greater than 1.\n",
        "        #       For probabilities greater than 1, set it equal to 1.\n",
        "        ## Insert your code BEGIN\n",
        "        probablity = []\n",
        "        for x in dist_k:\n",
        "            if x == 0:\n",
        "                probablity.append(1)\n",
        "            else:\n",
        "                prob = self.k / (2* len(x_train)* x)\n",
        "                probablity.append(min(prob, 1))\n",
        "\n",
        "        return probablity\n",
        "        # Return ...\n",
        "        ## Insert your code END\n",
        "    \n",
        "    # Gaussian part\n",
        "    def generate_avgs(self, X, y):\n",
        "        \"\"\"\n",
        "        Return mean for each class and for each attribute\n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        avgs = []\n",
        "        for clas in self.classes:\n",
        "            avgs.append(X[y==clas].mean(axis=0))\n",
        "\n",
        "        \n",
        "        avgs = np.array(avgs)\n",
        "        # avgs = np.transpose(avgs)\n",
        "        # print(\"avgs\",avgs)\n",
        "        return avgs\n",
        "      ## Insert your code END\n",
        "    \n",
        "    def generate_vars(self, X, y):\n",
        "        \"\"\"\n",
        "        Return variance for each class and for each attribute\n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        vars = []\n",
        "        for clas in self.classes:\n",
        "            vars.append(X[y==clas].var(axis=0))\n",
        "\n",
        "        vars = np.array(vars)\n",
        "        # vars = np.transpose(vars)\n",
        "        # print(\"vars\", np.array(vars))\n",
        "        return vars\n",
        "        ## Insert your code END\n",
        "        \n",
        "    # ## Insert your code BEGIN\n",
        "    # # Place any method you need here\n",
        "    # # def ...\n",
        "\n",
        "    # ## Insert your code END\n",
        "\n",
        "    def generate_guassian_likelihoods(self, X):\n",
        "        ## Insert your code BEGIN\n",
        "        likelihoods = np.zeros((X.shape[0], len(self.classes)))\n",
        "        # print(self.avgs.shape, self.vars.shape)\n",
        "        for i, c in enumerate(self.classes):\n",
        "            # print(i,c)\n",
        "            likelihoods[:, i] = np.prod(norm.pdf(X, loc=self.avgs[i], scale=np.sqrt(self.vars[i])), axis=1)              \n",
        "            # generate the likelihood using norm.pdf\n",
        "        return likelihoods\n",
        "        ## Insert your code END\n",
        "\n",
        "    def generate_knn_likelihoods(self, X):\n",
        "        \n",
        "        likelihoods = np.ones([len(self.classes), X.shape[0] ])\n",
        "        for i, aclass in enumerate(self.classes):\n",
        "            index = self.y_train == aclass\n",
        "            for attr in range(X.shape[1]):\n",
        "                ## Insert your code BEGIN\n",
        "                x_train = self.X_train[index, attr]\n",
        "                x_predict = X[:, attr]\n",
        "                likelihoods[i, :] *= self.knn_density_function(x_train, x_predict)\n",
        "                ## Insert your code END\n",
        "        likelihood = (np.transpose(likelihoods))\n",
        "        return likelihood\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # define the classes with ascending order\n",
        "        self.generate_classes(y)\n",
        "        # compute the Priori probability\n",
        "        self.generate_priors(y)\n",
        "        \n",
        "        # different likelihood function\n",
        "        if self.likelihood == 'normal':\n",
        "            # calculate the avg and var based on X and y\n",
        "            self.avgs = self.generate_avgs(X, y)\n",
        "            self.vars = self.generate_vars(X, y)\n",
        "        elif self.likelihood == 'knn':\n",
        "            self.X_train = X\n",
        "            self.y_train = y\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood. Must be \"normal\" or \"knn\".')\n",
        "        return self\n",
        "\n",
        "    def generate_likelihoods(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns probabilities at X (like X.shape[0] * Number of classes -> {Poss for each class} )\n",
        "        \"\"\"\n",
        "        # Gussian\n",
        "        if self.likelihood == \"normal\":\n",
        "            self.likelihoods = self.generate_guassian_likelihoods(X)\n",
        "        elif self.likelihood == \"knn\":\n",
        "            self.likelihoods = self.generate_knn_likelihoods(X)\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood Must be \"normal\" or \"knn\".')\n",
        "        return self.likelihoods\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns prediction\n",
        "        \"\"\"\n",
        "        # prediction = np.zeros((X.shape[0], len(self.classes)))\n",
        "        self.likelihoods = self.generate_likelihoods(X)\n",
        "        ## Insert your code BEGIN\n",
        "        # print(self.likelihoods.shape, self.priors.shape)\n",
        "        self.posteriors = self.likelihoods * self.priors\n",
        "        # print(self.posteriors.shape)\n",
        "        self.posteriors /= self.posteriors.sum(axis=1, keepdims=True)\n",
        "        prediction =  self.classes[np.argmax(self.posteriors, axis=1)]\n",
        "        ## Insert your code END\n",
        "        # print(\"prediction\", prediction)\n",
        "        return prediction\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        return accuracy_score(self.predict(X), y, sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "ab66369c",
      "metadata": {
        "id": "ab66369c"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "x = iris['data']\n",
        "y = iris['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "35d10faa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "0.96\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "clf = NaiveBayesClassifier(likelihood='normal')\n",
        "# clf.generate_classes(y)\n",
        "# clf.generate_priors(y)\n",
        "# clf.generate_avgs( x, y)\n",
        "# clf.generate_vars(x, y)\n",
        "clf.fit(x, y)\n",
        "clf.generate_guassian_likelihoods(x)\n",
        "accuracy = clf.score(x, y)\n",
        "print(accuracy)\n",
        "print(len(clf.avgs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "3e39f429",
      "metadata": {
        "id": "3e39f429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='normal')\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "HH-u9noQSaTm",
      "metadata": {
        "id": "HH-u9noQSaTm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "means:\n",
            " [[5.006 3.428 1.462 0.246]\n",
            " [5.936 2.77  4.26  1.326]\n",
            " [6.588 2.974 5.552 2.026]]\n",
            "\n",
            "variances:\n",
            " [[0.122 0.141 0.03  0.011]\n",
            " [0.261 0.097 0.216 0.038]\n",
            " [0.396 0.102 0.298 0.074]]\n",
            "\n",
            "prior probability:\n",
            " [0.333 0.333 0.333]\n",
            "\n",
            "likelihoods:\n",
            "[[8.682e+00 1.179e-17 6.175e-25]\n",
            " [4.569e+00 6.922e-17 1.073e-24]\n",
            " [3.554e+00 3.813e-18 8.316e-26]\n",
            " [3.312e+00 4.857e-17 9.788e-25]\n",
            " [8.255e+00 3.742e-18 2.381e-25]]\n",
            "[[1.830e-110 4.579e-002 1.116e-002]\n",
            " [2.020e-102 2.625e-001 1.523e-002]\n",
            " [1.804e-124 4.397e-002 5.242e-002]\n",
            " [1.401e-071 3.287e-001 1.027e-005]\n",
            " [5.307e-108 4.892e-001 2.443e-002]]\n",
            "[[2.292e-255 4.506e-012 7.093e-002]\n",
            " [1.876e-153 4.389e-003 1.711e-001]\n",
            " [4.443e-221 8.025e-008 4.779e-001]\n",
            " [4.306e-177 1.048e-003 5.246e-001]\n",
            " [2.174e-218 1.419e-007 6.156e-001]]\n",
            "\n",
            "posteriors:\n",
            "[[1.000e+00 1.358e-18 7.113e-26]\n",
            " [1.000e+00 1.515e-17 2.348e-25]\n",
            " [1.000e+00 1.073e-18 2.340e-26]\n",
            " [1.000e+00 1.466e-17 2.955e-25]\n",
            " [1.000e+00 4.533e-19 2.884e-26]]\n",
            "[[3.214e-109 8.040e-001 1.960e-001]\n",
            " [7.273e-102 9.452e-001 5.483e-002]\n",
            " [1.871e-123 4.562e-001 5.438e-001]\n",
            " [4.263e-071 1.000e+000 3.125e-005]\n",
            " [1.033e-107 9.524e-001 4.756e-002]]\n",
            "[[3.232e-254 6.354e-011 1.000e+000]\n",
            " [1.069e-152 2.501e-002 9.750e-001]\n",
            " [9.297e-221 1.679e-007 1.000e+000]\n",
            " [8.193e-177 1.995e-003 9.980e-001]\n",
            " [3.531e-218 2.305e-007 1.000e+000]]\n",
            "\n",
            "predictions:\n",
            "[0 0 0 0 0]\n",
            "[1 1 2 1 1]\n",
            "[2 2 2 2 2]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print(\"\\nmeans:\\n\", clf.avgs)\n",
        "\n",
        "print(\"\\nvariances:\\n\", clf.vars)\n",
        "\n",
        "print('\\nprior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "fab07350",
      "metadata": {
        "id": "fab07350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.78\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='knn', k=3)\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "gat41ucYeEAU",
      "metadata": {
        "id": "gat41ucYeEAU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prior probability:\n",
            " [0.333 0.333 0.333]\n",
            "\n",
            "likelihoods:\n",
            "[[6.750e-03 1.252e-05 1.206e-07]\n",
            " [3.375e-03 4.383e-05 2.138e-07]\n",
            " [1.012e-03 1.587e-06 2.649e-07]\n",
            " [5.625e-05 5.455e-06 1.476e-07]\n",
            " [1.125e-03 3.287e-06 1.764e-07]]\n",
            "[[6.328e-07 4.219e-05 1.808e-05]\n",
            " [8.766e-07 4.500e-03 1.558e-05]\n",
            " [3.800e-07 1.350e-02 2.755e-05]\n",
            " [3.429e-07 1.125e-03 3.600e-06]\n",
            " [2.639e-07 1.929e-03 1.607e-05]]\n",
            "[[3.297e-07 5.455e-05 1.620e-03]\n",
            " [1.442e-07 4.821e-05 3.375e-03]\n",
            " [1.289e-07 7.714e-05 5.625e-04]\n",
            " [2.171e-07 1.157e-04 1.157e-03]\n",
            " [1.744e-07 7.143e-05 7.418e-06]]\n",
            "\n",
            "posteriors:\n",
            "[[9.981e-01 1.852e-03 1.783e-05]\n",
            " [9.871e-01 1.282e-02 6.254e-05]\n",
            " [9.982e-01 1.565e-03 2.612e-04]\n",
            " [9.094e-01 8.819e-02 2.386e-03]\n",
            " [9.969e-01 2.913e-03 1.563e-04]]\n",
            "[[1.039e-02 6.927e-01 2.969e-01]\n",
            " [1.941e-04 9.964e-01 3.449e-03]\n",
            " [2.809e-05 9.979e-01 2.037e-03]\n",
            " [3.037e-04 9.965e-01 3.189e-03]\n",
            " [1.357e-04 9.916e-01 8.263e-03]]\n",
            "[[1.968e-04 3.257e-02 9.672e-01]\n",
            " [4.213e-05 1.408e-02 9.859e-01]\n",
            " [2.015e-04 1.206e-01 8.792e-01]\n",
            " [1.705e-04 9.089e-02 9.089e-01]\n",
            " [2.207e-03 9.039e-01 9.387e-02]]\n",
            "\n",
            "predictions:\n",
            "[0 0 0 0 0]\n",
            "[1 1 1 1 1]\n",
            "[2 2 2 2 1]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print('prior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68aHXBEdeZzO",
      "metadata": {
        "id": "68aHXBEdeZzO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
